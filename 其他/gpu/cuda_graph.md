---
title: cuda graph
---

近年来，随着 GPU 架构的不断更迭，其性能也越来越好，那些个 GPU 操作(比如 CUDA Kernel 或者 Memory copy)所花费的时间习惯都以微秒为单位进行测量。而不可忽视的一个问题就是 kernel launch 的时间，将每个操作提交给 GPU 也会产生开销，通常是微妙级的。如果在实际应用程序中存在大量 GPU 操作，那么 kernel launch 时间将不可忽略，如此必然会影响整体端到端性能。

cuda graph 设计初衷就是为了解决如上问题，它允许将工作任务定义为图，而不是单个操作，提供了一种通过单个 CPU 操作启动多个 GPU 操作的机制来解决上述问题，从而减小开销。

Graphs 由一系列操作构成，例如内核启动等，并通过依赖关系连接，同时图的定义和执行彼此独立。这使得一个 Graphs 可以一次定义，多次启动。将 Graphs 的定义与执行分开可以实现许多优化：首先，与 Stream 相比，因为大部分设置都是提前完成的，故降低了 CPU 的启动成本；其次，Graph 可以将整个工作流呈现给 CUDA ，CUDA 可以对其进行优化，而这对于 Stream的分段工作提交机制来说可能无法实现。

为了更好的理解 Graphs 为什么可以优化，请考虑使用 Stream 的情况：当您将内核放入 Stream 中，主机驱动程序会执行一系列操作，准备在 GPU 上执行内核。这些操作是设置和启动内核所必需的，它们是每个内核执行时所必须支付的间接成本。对于执行时间较短的 GPU 内核，这种开销可能就占到了很大一部分的端到端执行时间。

使用 Graphs 的工作提交分为三个阶段：定义、实例化和执行。

- 在定义阶段，程序创建 Graph 中操作的描述以及它们之间的依赖关系。
- 实例化获取 Graph 模板的快照，对其进行验证，并执行大部分的设置和初始化工作，目的是最大限度地减少启动时所需要的工作。 生成的实例称为可执行图 (Executable Graph)。
- Executable Graph 可以在 Stream 中启动，与任何其他的 CUDA 工作类似。它可以在不重复实例化的情况下启动任意多次。

一个操作就是 Graph 中的一个节点。 操作之间的依赖关系是边。 这些依赖关系限制了操作的执行顺序。

一个操作可以在它所依赖的节点完成后随时调度。 调度由 CUDA 系统决定。

























