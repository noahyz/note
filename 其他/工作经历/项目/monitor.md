## Monitor

量级：承载了 100w 左右的服务器和 2w多个视图的监控

上报数据模型 `{(server_id, attr_id, timestamp) -> value}` 或者 ` {(server_id, attr_id) -> value[n]} ` 通常将 timestamp 离散化为 1440 分钟，系统的采集数据的最小粒度为 1 分钟，此时数据模型如后者，其中 n 为 timestamp 离散化后对应的分钟下标。

基础数据构成

- 服务器的监控数据： ` (server_id, attr_id) -> value[0-1439] `
- 视图的监控数据： `(view_id, attr_id) -> value[0-1439]`

### 一、架构设计







### 工作经历

**主要工作：参与Monitor系统的优化、迭代、运维等工作**

l Monitor 对外API接口模块重构&开发，解决了Monitor以前拉取数据、获取配置的API接口存在的版本较多、各版本工具接口或功能不全、请求参数格式或返回数据格式复杂等问题。而对接口统一梳理，设计可插拔式的插件型框架，便于新增/更新API接口，提高业务接入效率 

l Monitor告警模块重构&开发，以前告警消息存储于数据库，按照定长时间戳读取发送，容易出现消息堆积、告警延时较大、下游（tof）接口限额导致告警丢失等问题。后续对消息进行过滤、聚合后发送，例如：合并相同接收人的消息后发送、重复消息降低发送频率等。消息总量减少35%

l 搭建部署海外Monitor系统集群，进行数据的同步与切割，适配海外IOA鉴权、CMDB同步数据、tof告警等，及时交付业务接入使用


API模块的设计与开发：使用缓存作为数据库的中介，提高系统的性能和吞吐量；采用Cache-Aside Pattern的缓存更新策略，尽可能地保证缓存中的数据是最新的，同时也尽可能的解决缓存与数据库的数据不一致问题。针对写接口限频，参考类似滑动时间窗口的限流算法，对于同一用户调用同一写接口的时间间隔必须大于一秒，做到最省成本且最大可能的保护系统的数据库负载不会太高。

查询接口的QPS：5w/s，资源占用：2C  
新增
更新
删除
查询
为什么不用 redis，用不起，成本高。写接口限频非分布式，限频不准

告警模块的重构与开发：针对之前的告警服务存在消息未聚合、不同时间间隔存在重复的消息导致每次待发送的消息数量多，使下游发送消息接口经常性的触发限频，最终可能导致告警消息丢失，严重影响用户的使用。后续对相同时间间隔（1分钟）的告警消息进行聚合（合并相同接收人的消息），过滤掉不同时间间隔的重复消息，优化发送告警的策略。
原来的平均发送告警消息总量约为30w/d，优化后约为19w/d

告警模块重构，原来的消息总量：平时每天30w左右，后来差不多每天6k-7k左右，并且设置了分布式。过滤：字符串告警。  tof接口每天最多发送20w。