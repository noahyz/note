producer和consumer对于消息的交付可靠性保障

```
1. 最多一次：消息可能会丢失，但绝不会被重复发送
2. 至少一次：消息不会丢失，但有可能被重复发送
3. 精确一次：消息不会丢失，也不会被重复发送
kafka默认提供的交付可靠性是至少一次。比如出现网络瞬时抖动，Broker的应答没有成功发送回Producer端。那就需要Producer重复发送
```

kafka如何做到消息精确一次呢？机制：幂等性和事务

幂等性

```
在数学中，幂等的意思为：执行某个操作或函数能够执行多次，但每次得到的结果都是不变的。幂等最大的优势在于我们可以安全地重试任何幂等性操作，反正他们也不会破坏我们的系统状态。
幂等性是kafka 0.11.0.0 版本引入的新功能
指定幂等性：props.put("enable.idempotence", true) 或 props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true)

幂等性的作用范围：（幂等性Producer）
1. 一个幂等性Producer能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。
2. 它只能实现单会话上的幂等性，不能实现跨会话的幂等性。会话可以理解为Producer进程的一次运行，当重启了Producer进程之后，幂等性会消失。
```

事务型Producer

```
事务性Producer：实现多分区以及多会话的消息无重复，而且不怕Producer重启
设置事务型Producer，需要满足两个条件：
1. 和幂等性Producer一样，开启 enable.idempotence=true
2. 设置Producer端参数transactional.id，最好为其设置一个有意义的名字
Producer代码也需要做一些调整

producer.initTransactions(); // 事务初始化
try {
            producer.beginTransaction();  // 事务开始
            producer.send(record1);  
            producer.send(record2);
            producer.commitTransaction(); // 事务提交
} catch (KafkaException e) {
            producer.abortTransaction(); // 事务终止 
}
这段代码可以保证 Record1 和 Record2 被当作一个事务统一提交到kafka，要么他们全部提交成功，要么全部提交失败。

consumer端需要设置isolation.level参数的值：这个参数有两个取值
1. read_uncommitted：默认值，表明consumer能够读取到kafka写入的任何消息，不论事务型Producer提交事务还是终止事务，其写入的消息都可以读取
2. read_committed：表明consumer只会读取事务型Producer成功提交事务写入的消息。它也能看到非事务型Producer写入的消息
因为事务型Producer即使写入失败，kafka也会把他们写入到底层的日志中，也就是consumer还是会看到这些消息。
```

