消费者组：consumer Group是kafka提供的可扩展且具有容错性的消费者机制

```
1. Consumer Group 下可以有一个或多个Consumer实例。这里的实例可以是一个单独的进程，也可以是同一个进程下的线程。
2. Group ID是一个字符串，在一个kafka集群中，它标识唯一的一个Consumer Group
3. Consumer Group下所有实例订阅的主题的单个分区，只能分配给组内的某个Consumer实例消费。这个分区当然也可以被其他的Group消费

kafka仅仅使用Consumer Group这一种机制，却同时实现了传统消息引擎系统的两个模型：如果所有实例都属于一个Group，那么它实现的就是消息队列模型；如果所有实例分别属于不同的Group，那么它实现的就是发布/订阅模型。

理想情况，Consumer实例的数量应该等于该Group订阅主题的分区总数。如果实例数量太多，则有些实例永远处于空闲状态；如果实例数量太少，那实例可能需要消费多个分区。

对于消费位移(KV{分区，位移})，kafka将位移保存在kafka内部主题 __consumer_offsets 中
```

消费者组重平衡机制

```
目的：规定了一个Consumer Group下的所有Consumer如何达成一致，来分配订阅Topic的每个分区。
触发条件：
1. 组成员数发生变更。比如有新的Consumer实例加入组或者离开组，抑或是有Consumer实例奔溃被“踢出”组
2. 订阅主题数发送变更。Consumer Group可以使用正则表达式的方式订阅主题，比如consumer.subscrible(Pattern.compile("t.*c")) 就表明该Group订阅所有以字母t开头、字母c结尾的主题。在Consumer Group的运行过程中，新创建一个满足这样条件的主题，那么该Group就会发生Rebalance
3. 订阅主题的分区数发生变更。kafka当前只能允许增加一个主题的分区数，当分区数增加时，就会触发订阅该主题的所有Group开启Rebalance
缺点：
1. 在Rebalance过程中，所有Consumer实例都会停止消费，等待Rebalance完成。
2. 在Rebalance的设计中所有的Consumer实例会共同参与，全部重新分配所有分区，其实高效的做法是尽量减少分配方案的变动
3. Rebalance实在特别慢，应该避免Rebalance的出现
```

kafka内部的位移主题 __consumer_offsets 

```
位移主题的Key中应该保存3部分内容：<GroupID, 主题名，分区号>，value除了位移值，还有时间戳、用户自定义的数据等。

当kafka集群中的第一个Consumer程序启动时，kafka会自动创建位移主题。此主题的分区数由Broker端参数 offsets.topic.num.partitions决定，默认值为50。kafka的日志路径中会有 __consumer_offsets-xxx 这样的目录。副本数由参数 offsets.topic.replication.factor决定，默认值为3
```

提交位移：自动提交位移和手动提交位移

```
Consumer端参数: enable.auto.commit 
为true：Consumer在后台定期提交位移，提交间隔由参数：auto.commit.interval.ms来控制
为false：手动提交位移，Consumer API提供方法：consumer.commitSync等，当调用这些方法时，kafka会向位移主题写入相应消息

自动提交位移的问题：只要consumer一直启动，他就会无限期的向位移主题写入消息
kafka使用compact策略来删除位移主题中的过期消息，kafka提供专门的后台线程定期的巡检待compact的主题，看看是否存在满足条件的可删除数据。这个后台进程是Log Cleaner。
```

